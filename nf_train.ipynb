{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "from glob import glob\n",
    "\n",
    "import align.detect_face\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy import misc\n",
    "from scipy.interpolate import Rbf\n",
    "from skimage import io, transform\n",
    "from six.moves import xrange\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "import facenet\n",
    "import helper\n",
    "\n",
    "#Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.ion() # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks_frame = pd.read_csv('./face_landmarks_generate.csv')\n",
    "file_list = landmarks_frame.image_name.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgP_container = np.load('f_avgP_list.npz')\n",
    "emb_container = np.load('f_emb_list.npz')\n",
    "\n",
    "train_set = []\n",
    "test_set = []\n",
    "\n",
    "for key in sorted(emb_container, key=lambda x: int(x.strip('arr_'))) :\n",
    "    batch = avgP_container[key], emb_container[key]\n",
    "    if len(batch[0]) is batch_size :\n",
    "        train_set.append(batch)\n",
    "    else :\n",
    "        test_set.append(batch)\n",
    "\n",
    "test_set_index = len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7867, 160, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "t_dataset = helper.Dataset('nf',file_list, 160)\n",
    "print(t_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_layer(encoded, f_num = 128) : \n",
    "    with tf.variable_scope('F') :\n",
    "        fc = slim.fully_connected(encoded, f_num, activation_fn=tf.nn.relu, scope='fc')\n",
    "    return fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(net, landmark_num = 68, reuse=None, scope='MLP'):\n",
    "    \"\"\"Builds the MLP for landmark\"\"\"\n",
    "    with tf.variable_scope(scope, 'MLP') :\n",
    "        net = slim.fully_connected(net, 256, activation_fn=None, scope='fc0')\n",
    "        net = slim.fully_connected(net, 128, activation_fn=None, scope='fc1')\n",
    "        net = slim.fully_connected(net, landmark_num, activation_fn=tf.nn.relu, scope='fc2')\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def landmark_decode(net, landmark_num = 68):\n",
    "    with tf.variable_scope('landmark') :\n",
    "        decoded_x = MLP(net, scope= 'decoded_x')\n",
    "        decoded_y = MLP(net, scope= 'decoded_y')\n",
    "    return decoded_x, decoded_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(F, size) :\n",
    "    with tf.variable_scope('CNN') :\n",
    "        # 12 x 12 x 256\n",
    "        f_size = int(size / 8)\n",
    "        features = slim.fully_connected(F, f_size * f_size * 256, activation_fn=None, scope=\"features\")\n",
    "        features = tf.reshape(features, [-1, f_size, f_size, 256])\n",
    "        # print(features.shape)\n",
    "        \n",
    "        # 24 x 24 x 128\n",
    "        upsample_0 = slim.conv2d_transpose(features, 128, 5, stride=2, scope=\"upsample_0\")\n",
    "        # print(upsample_0.shape)\n",
    "        \n",
    "        # 48 x 48 x 64\n",
    "        upsample_1 = slim.conv2d_transpose(upsample_0, 64, 5, stride=2, scope=\"upsample_1\")\n",
    "        # print(upsample_1.shape)\n",
    "        \n",
    "        # 96 x 96 x 32\n",
    "        upsample_2 = slim.conv2d_transpose(upsample_1, 32, 5, stride=2, scope=\"upsample_2\")\n",
    "        # print(upsample_2.shape)\n",
    "        \n",
    "        # 96 x 96 x 3\n",
    "        one_by_one_conv = slim.conv2d(upsample_2, 3, 1, stride=1, activation_fn=None, scope=\"one_by_one_conv\")\n",
    "        # print(one_by_one_conv.shape)\n",
    "    return one_by_one_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def texture_decode(encoded, size) :\n",
    "    with tf.variable_scope('texture') :\n",
    "        cnn = CNN(F, size)\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grids(size):\n",
    "    return np.mgrid[0:size-1:(size * 1j), 0:size-1:(size * 1j)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zero_displacement(size, landmarks):\n",
    "    mid = size/2\n",
    "    end = size-1\n",
    "    \n",
    "    new_landmarks = np.copy(landmarks)\n",
    "    new_landmarks[:, 0][27:31] += 5\n",
    "#     new_landmarks[:, 1][27:31] += 5\n",
    "    \n",
    "    zero_displacement = [[0,0], \n",
    "                         [0, mid], \n",
    "                         [0, end], \n",
    "                         [mid, 0], \n",
    "                         [end,0], \n",
    "                         [end, mid], \n",
    "                         [end, end], \n",
    "                         [mid, end]]\n",
    "    \n",
    "    landmarks_with_zero_displacement = np.append(landmarks, zero_displacement, axis=0)\n",
    "    new_landmarks_with_zero_displacement = np.append(new_landmarks, zero_displacement, axis=0)\n",
    "    return landmarks_with_zero_displacement, new_landmarks_with_zero_displacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_tf(pred_x, pred_y, correct_points, grids, grid_shape, batch_size):\n",
    "    def _euclidean_norm_tf(x1, x2):    \n",
    "        return tf.sqrt(tf.reduce_sum(((x1 - x2)**2), 1))\n",
    "\n",
    "    def _h_linear_tf(r):\n",
    "        return r\n",
    "\n",
    "    def _call_norm_tf(x1, x2):\n",
    "        x1 = tf.expand_dims(x1, 3) \n",
    "        x2 = tf.expand_dims(x2, 2) \n",
    "        return norm(x1, x2)    \n",
    "\n",
    "    # set parameters\n",
    "    norm = _euclidean_norm_tf\n",
    "    basis_function = _h_linear_tf\n",
    "    epsilon = tf.constant(2.)\n",
    "    smooth = tf.constant(1.)\n",
    "\n",
    "    xi = tf.concat([tf.expand_dims(pred_x, 1), tf.expand_dims(pred_y, 1)], 1) # (None, 2, 76)\n",
    "    N = xi.shape[-1].value # same as landmarks_num => 76\n",
    "    di = tf.expand_dims(correct_points, 2) # (None, 76, 1)\n",
    "    \n",
    "    r = _call_norm_tf(xi, xi) # (None, 76, 76)\n",
    "    \n",
    "    batch_shape = tf.shape(pred_x)[0:1]\n",
    "    A = tf.subtract(basis_function(r), tf.multiply(smooth, tf.eye(N, batch_shape= batch_shape)))\n",
    "    #A = tf.subtract(basis_function(r), tf.multiply(smooth, tf.eye(N, batch_shape= [batch_size])))\n",
    "    nodes = tf.matrix_solve (A, di)\n",
    "    r2 = _call_norm_tf(grids, xi)\n",
    "    return tf.reshape(tf.matmul(r2, nodes), [-1, grid_shape[0], grid_shape[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_tf(data, pred_x, pred_y, correct_x, correct_y, grids, grid_shape, batch_size) :\n",
    "    rbf_x = rbf_tf(pred_x, pred_y, correct_x, grids, grid_shape, batch_size)\n",
    "    rbf_y = rbf_tf(pred_x, pred_y, correct_y, grids, grid_shape, batch_size)\n",
    "    warp = tf.concat([tf.expand_dims(rbf_x, 3), tf.expand_dims(rbf_y, 3)], axis=3)\n",
    "    resample = tf.contrib.resampler.resampler(data=data, warp=warp)\n",
    "    return resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "\n",
    "avgP_num = 1792\n",
    "emb_num = 128\n",
    "f_num = 512 #1024\n",
    "\n",
    "l_num = 68\n",
    "zd_l_num = 74\n",
    "t_size = 160\n",
    "t_channel = 3\n",
    "\n",
    "grid_y, grid_x = get_grids(t_size)\n",
    "grid_shape = grid_x.shape\n",
    "xa = np.asarray([a.flatten() for a in [grid_x, grid_y]], dtype=np.float_) # (2, 25600)\n",
    "xa = np.asarray([xa for _ in range(0, batch_size)], dtype=np.float_) # (batch_size, 2, 25600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    # placeholder\n",
    "    avgP_inputs = tf.placeholder(tf.float32, (None, avgP_num), name='avgP_inputs')\n",
    "    \n",
    "    l_x_labels = tf.placeholder(tf.float32, (None, l_num), name='l_x_labels')\n",
    "    l_y_labels = tf.placeholder(tf.float32, (None, l_num), name='l_y_labels')\n",
    "    t_labels = tf.placeholder(tf.float32, (None, t_size, t_size, t_channel), name='t_labels')\n",
    "    w_labels = tf.placeholder(tf.float32, shape=(None, emb_num), name= 'w_labels')\n",
    "    \n",
    "    grids = tf.constant(xa, dtype=tf.float32, name= 'grids')\n",
    "    \n",
    "    # model\n",
    "    F = F_layer(avgP_inputs, f_num= f_num)\n",
    "    \n",
    "    (l_x_preds, l_y_preds) = landmark_decode(F, landmark_num= l_num)\n",
    "    \n",
    "    l_x_loss = tf.losses.mean_squared_error(l_x_labels, l_x_preds, reduction=\"weighted_mean\")\n",
    "    l_y_loss = tf.losses.mean_squared_error(l_y_labels, l_y_preds, reduction=\"weighted_mean\")\n",
    "    \n",
    "    l_loss = tf.add(l_x_loss, l_y_loss)\n",
    "    \n",
    "    t_preds = texture_decode(F, t_size)\n",
    "    t_loss = tf.losses.absolute_difference(t_labels, t_preds)\n",
    "    \n",
    "    warp = warp_tf(t_preds, l_x_preds, l_y_preds, l_x_labels, l_y_labels, grids, grid_shape, batch_size)\n",
    "    cast_warp = tf.cast(warp, tf.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1507875598.88635 start load facenet ---\n",
      "Model filename: ./20171012\n",
      "--- 3.634227752685547 facenet loaded ---\n"
     ]
    }
   ],
   "source": [
    "with g.as_default():\n",
    "    time_load_data = time.time()\n",
    "    \n",
    "    #facenet\n",
    "    start_load_facenet = time.time()\n",
    "    print(\"--- %s start load facenet ---\" % (start_load_facenet))\n",
    "    facenet.load_model('./20171012', input_map={\"input:0\": warp})\n",
    "    print(\"--- %s facenet loaded ---\" % (time.time() - start_load_facenet))\n",
    "\n",
    "    f_phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "    w_preds = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")    \n",
    "    w_loss = tf.losses.cosine_distance(tf.nn.l2_normalize(w_labels, 1), \n",
    "                                       tf.nn.l2_normalize(w_preds, 1), dim=1)\n",
    "    \n",
    "    total_cost = l_loss + t_loss + w_loss\n",
    "    opt = tf.train.AdamOptimizer(0.001).minimize(total_cost)\n",
    "    \n",
    "    variables = [v for v in tf.global_variables()]\n",
    "    init = tf.variables_initializer(var_list= variables, name= 'init')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_landmarks(image, landmarks):\n",
    "    plt.imshow(image)\n",
    "    plt.scatter(landmarks[:, 0], landmarks[:, 1], s=10, marker='.', c='b')\n",
    "    plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_test(l_x, l_y, t, w, index):\n",
    "    index = len(train_set) * batch_size + index\n",
    "    img_name = landmarks_frame.ix[index, 0]\n",
    "    landmarks = landmarks_frame.ix[n, 1:].as_matrix().astype('float')\n",
    "    landmarks = landmarks.reshape(-1, 2) # (68, 2)\n",
    "    \n",
    "    plt.figure()\n",
    "    show_landmarks(io.imread(os.path.join('', img_name)), landmarks)\n",
    "    plt.show()\n",
    "    \n",
    "    t_img = scipy.misc.toimage(t)\n",
    "    plt.imshow(t_img)\n",
    "    plt.scatter(l_x, l_y, s=10, marker='.', c='b')\n",
    "    plt.pause(0.001)\n",
    "    plt.show()\n",
    "    \n",
    "#     plt.imshow(np.squeeze(w, axis=0))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-68e52d67390e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m                              f_phase_train_placeholder:False}\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0ml_x_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_y_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 print(\"Epoch: {}/{}...\".format(e+1, epochs),                          \"Training loss: X = {:.4f}, Y = {:.4f}, T = {:.4f}, W = {:.4f}\".format(l_x_cost / size, \n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with g.as_default():\n",
    "    with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "        print(sess.run(init))\n",
    "        start_test = time.time()\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            for i, ((f_avgP, f_emb), t_label_batch) in enumerate(zip(train_set, t_dataset.get_batches(batch_size))):\n",
    "                start = i * batch_size\n",
    "                end = min(start+batch_size, len(train_set) * batch_size)\n",
    "                size = end - start\n",
    "\n",
    "                l_labels = landmarks_frame.ix[start:end - 1, 1:].as_matrix().astype('float').reshape(-1, 2)\n",
    "\n",
    "                run = [l_x_loss, l_y_loss, t_loss, w_loss, opt]\n",
    "                feed_dict = {avgP_inputs : f_avgP.reshape(-1, avgP_num),\n",
    "                             l_x_labels : l_labels[:, 0].reshape(-1, l_num), \n",
    "                             l_y_labels : l_labels[:, 1].reshape(-1, l_num),\n",
    "                             t_labels : t_label_batch, \n",
    "                             w_labels : f_emb, \n",
    "                             f_phase_train_placeholder:False}\n",
    "\n",
    "                l_x_cost, l_y_cost, t_cost, w_cost, _ = sess.run(run, feed_dict= feed_dict)\n",
    "                \n",
    "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\\\n",
    "                          \"Training loss: X = {:.4f}, Y = {:.4f}, T = {:.4f}, W = {:.4f}\".format(l_x_cost / size, \n",
    "                                                                                                 l_y_cost / size, \n",
    "                                                                                                 t_cost, \n",
    "                                                                                                 w_cost))\n",
    "            test_index = random.randint(0, len(test_set[0])-1)\n",
    "            test_avgP = test_set[0][test_index]\n",
    "            test_run = [l_x_preds, l_y_preds, t_preds]\n",
    "            test_feed = {avgP_inputs : test_avgP.reshape(-1, avgP_num)}\n",
    "            t_l_x, t_l_y, t_t = sess.run(test_run, feed_dict= test_feed)\n",
    "            show_test(t_l_x, t_l_y, t_t, test_index)\n",
    "            print(\"Time: %s\" % (time.time() - start_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeding Facenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_align_data(image_paths, image_size, margin, gpu_memory_fraction):\n",
    "\n",
    "    minsize = 20 # minimum size of face\n",
    "    threshold = [ 0.6, 0.7, 0.7 ]  # three steps's threshold\n",
    "    factor = 0.709 # scale factor\n",
    "    \n",
    "    print('Creating networks and loading parameters')\n",
    "    with tf.Graph().as_default():\n",
    "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_memory_fraction)\n",
    "        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\n",
    "        with sess.as_default():\n",
    "            pnet, rnet, onet = align.detect_face.create_mtcnn(sess, None)\n",
    "  \n",
    "    nrof_samples = len(image_paths)\n",
    "    img_list = [None] * nrof_samples\n",
    "    for i in range(nrof_samples):\n",
    "        img = misc.imread(os.path.expanduser(image_paths[i]))\n",
    "        if (img.shape[2] == 4):\n",
    "            img = img[:, :, :3]\n",
    "        img_size = np.asarray(img.shape)[0:2]\n",
    "        bounding_boxes, _ = align.detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)\n",
    "        det = np.squeeze(bounding_boxes[0,0:4])\n",
    "        bb = np.zeros(4, dtype=np.int32)\n",
    "        bb[0] = np.maximum(det[0]-margin/2, 0)\n",
    "        bb[1] = np.maximum(det[1]-margin/2, 0)\n",
    "        bb[2] = np.minimum(det[2]+margin/2, img_size[1])\n",
    "        bb[3] = np.minimum(det[3]+margin/2, img_size[0])\n",
    "        cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\n",
    "        aligned = misc.imresize(cropped, (image_size, image_size), interp='bilinear')\n",
    "        prewhitened = facenet.prewhiten(aligned)\n",
    "        img_list[i] = prewhitened\n",
    "        sys.stdout.write('\\r'+ '%d/%d'%(i, nrof_samples))\n",
    "    images = np.stack(img_list)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "f_emb_g = tf.Graph()\n",
    "f_emb_list = []\n",
    "f_avgP_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- data loading start ---\n",
      "Creating networks and loading parameters\n",
      "7866/7867--- 221.59326314926147 data loaded ---\n",
      "--- 1507870378.9542003 start load facenet ---\n",
      "Model filename: ./20171012\n",
      "--- 4.037825107574463 facenet loaded ---\n",
      "[0/7867] 4.5784010887146\n",
      "[100/7867] 5.2621378898620605\n",
      "[200/7867] 5.945639133453369\n",
      "[300/7867] 6.6299684047698975\n",
      "[400/7867] 7.314805746078491\n",
      "[500/7867] 7.998567819595337\n",
      "[600/7867] 8.683316469192505\n",
      "[700/7867] 9.368604898452759\n",
      "[800/7867] 10.052686929702759\n",
      "[900/7867] 10.732678651809692\n",
      "[1000/7867] 11.416769981384277\n",
      "[1100/7867] 12.100522756576538\n",
      "[1200/7867] 12.785982131958008\n",
      "[1300/7867] 13.469927549362183\n",
      "[1400/7867] 14.15501356124878\n",
      "[1500/7867] 14.839283466339111\n",
      "[1600/7867] 15.523703336715698\n",
      "[1700/7867] 16.209466457366943\n",
      "[1800/7867] 16.894711017608643\n",
      "[1900/7867] 17.575763702392578\n",
      "[2000/7867] 18.26040482521057\n",
      "[2100/7867] 18.94400978088379\n",
      "[2200/7867] 19.62877655029297\n",
      "[2300/7867] 20.31416368484497\n",
      "[2400/7867] 20.99917984008789\n",
      "[2500/7867] 21.683804035186768\n",
      "[2600/7867] 22.368025541305542\n",
      "[2700/7867] 23.052414894104004\n",
      "[2800/7867] 23.736844778060913\n",
      "[2900/7867] 24.419987440109253\n",
      "[3000/7867] 25.104164361953735\n",
      "[3100/7867] 25.788164377212524\n",
      "[3200/7867] 26.472842931747437\n",
      "[3300/7867] 27.15757393836975\n",
      "[3400/7867] 27.840853929519653\n",
      "[3500/7867] 28.52486300468445\n",
      "[3600/7867] 29.206793308258057\n",
      "[3700/7867] 29.8872287273407\n",
      "[3800/7867] 30.570945262908936\n",
      "[3900/7867] 31.255260467529297\n",
      "[4000/7867] 31.941049098968506\n",
      "[4100/7867] 32.62586998939514\n",
      "[4200/7867] 33.31062030792236\n",
      "[4300/7867] 33.99514985084534\n",
      "[4400/7867] 34.67843461036682\n",
      "[4500/7867] 35.363258600234985\n",
      "[4600/7867] 36.04683017730713\n",
      "[4700/7867] 36.734660625457764\n",
      "[4800/7867] 37.41808557510376\n",
      "[4900/7867] 38.10238695144653\n",
      "[5000/7867] 38.78743767738342\n",
      "[5100/7867] 39.47177982330322\n",
      "[5200/7867] 40.15627121925354\n",
      "[5300/7867] 40.840903759002686\n",
      "[5400/7867] 41.52538084983826\n",
      "[5500/7867] 42.21089315414429\n",
      "[5600/7867] 42.89511799812317\n",
      "[5700/7867] 43.578827142715454\n",
      "[5800/7867] 44.26252579689026\n",
      "[5900/7867] 44.95069885253906\n",
      "[6000/7867] 45.635050773620605\n",
      "[6100/7867] 46.31951856613159\n",
      "[6200/7867] 47.00446605682373\n",
      "[6300/7867] 47.684518337249756\n",
      "[6400/7867] 48.369630336761475\n",
      "[6500/7867] 49.05533051490784\n",
      "[6600/7867] 49.74012851715088\n",
      "[6700/7867] 50.42446231842041\n",
      "[6800/7867] 51.10767459869385\n",
      "[6900/7867] 51.788097858428955\n",
      "[7000/7867] 52.472161531448364\n",
      "[7100/7867] 53.15648698806763\n",
      "[7200/7867] 53.83985662460327\n",
      "[7300/7867] 54.52419972419739\n",
      "[7400/7867] 55.208199977874756\n",
      "[7500/7867] 55.892210245132446\n",
      "[7600/7867] 56.57578110694885\n",
      "[7700/7867] 57.2610297203064\n",
      "[7800/7867] 59.55885171890259\n",
      "--- 59.55897331237793 seconds ---\n"
     ]
    }
   ],
   "source": [
    "with f_emb_g.as_default():\n",
    "    time_load_data = time.time()\n",
    "    print(\"--- data loading start ---\")\n",
    "    images = load_and_align_data(file_list, 160, 44, 1.0)\n",
    "    print(\"--- %s data loaded ---\" % (time.time() - time_load_data))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        start_load_facenet = time.time()\n",
    "        print(\"--- %s start load facenet ---\" % (start_load_facenet))\n",
    "        facenet.load_model('./20171012')\n",
    "        print(\"--- %s facenet loaded ---\" % (time.time() - start_load_facenet))\n",
    "\n",
    "        # Get input and output tensors\n",
    "        f_inputs = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "        f_phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "        f_avgP_logits = tf.get_default_graph().get_tensor_by_name(\"InceptionResnetV1/Logits/AvgPool_1a_8x8/AvgPool:0\")\n",
    "        f_emb_logits = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "        \n",
    "        start_test = time.time()\n",
    "        \n",
    "        total_size = len(images)\n",
    "        for i in range(0, total_size, batch_size):\n",
    "            batch = images[i:min(i+batch_size, total_size)]\n",
    "            f_feed = {f_inputs: batch, f_phase_train_placeholder:False}\n",
    "            f_embedings, f_avgPool = sess.run([f_emb_logits, f_avgP_logits], feed_dict=f_feed)\n",
    "            f_emb_list.append(f_embedings)\n",
    "            f_avgP_list.append(f_avgPool)\n",
    "            sys.stdout.write('\\r'+ \"[%d/%d] %s\" % (i, total_size, time.time() - start_test))\n",
    "            print()\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('f_emb_list.npz', *f_emb_list)\n",
    "np.savez('f_avgP_list.npz', *f_avgP_list)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
